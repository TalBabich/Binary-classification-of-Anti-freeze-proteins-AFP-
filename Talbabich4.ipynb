{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Talbabich4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlVD9KBu_MRm"
      },
      "source": [
        "## import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "##graphics\n",
        "import seaborn as sns \n",
        "\n",
        "## tensorflow and keras\n",
        "import math\n",
        "import sklearn\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, balanced_accuracy_score, roc_auc_score, make_scorer, confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import xgboost as xgb\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAjJDw1AGHdA"
      },
      "source": [
        "**no need to run those cells each time**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvaXEi6uCZrw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w26cuVRwFxOk"
      },
      "source": [
        "loading the data into splited arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO39KxtA_MRx"
      },
      "source": [
        "## loading the data\n",
        "def loadfile(name):\n",
        "    with open(name) as f:\n",
        "        data = pd.read_csv(f, delimiter=\",\", dtype={\"Id\": str})\n",
        "    labels = data[\"label\"].values\n",
        "    Ids = data[\"Id\"].values\n",
        "    data.drop(labels = [\"Id\", \"label\", 'Feature0'], axis=1, inplace = True)\n",
        "    features = data.values\n",
        "    return (features, labels, Ids)\n",
        "\n",
        "train_data, train_labels, train_Ids = loadfile(\"/content/drive/MyDrive/train.csv\")\n",
        "test_data, test_labels, test_Ids = loadfile(\"/content/drive/MyDrive/test.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgGfWSRKGBbM"
      },
      "source": [
        "loading the data into DataFrame in order to better understand it\n",
        "\n",
        "\n",
        "\n",
        "*  dropping Feature0 - all values are 0.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy7GQ2KH_MRy"
      },
      "source": [
        "##describing the data\n",
        "train_Data_1=pd.read_csv('/content/drive/MyDrive/train.csv')\n",
        "test_Data_1=pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "train_Data_1.drop('Feature0', axis=1, inplace=True)\n",
        "test_Data_1.drop('Feature0', axis=1, inplace=True)\n",
        "corr = train_Data_1.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvvsYoESPiC-"
      },
      "source": [
        "f, ax = plt.subplots(figsize=(12, 12))\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "sns.heatmap(corr, cmap=cmap, vmax=.3, center=0, square=True, cbar_kws={\"shrink\": .5},annot=False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAQJikGYwkU_"
      },
      "source": [
        "#spliting the data into train and validation sets\n",
        "x_train , x_validation ,y_train, y_validation = train_test_split(train_data,train_labels, random_state=42, test_size=0.2, stratify=train_labels, shuffle=True)\n",
        "evalset = [(x_train, y_train), (x_validation,y_validation)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPbjFgpNFwSE"
      },
      "source": [
        "## Building the XGBmodel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uAj-Pk1HAMF"
      },
      "source": [
        "#building the XGBoost model:\n",
        "#model = xgb.XGBClassifier(max_depth=10, eta=0.1, objective='binary:logistic',epochs=100, n_rounds=50, verbosity=1)\n",
        "model = xgb.XGBClassifier(alpha=0.5, base_score=0.5, booster='gbtree',colsample_bylevel=0.8, \n",
        "                          colsample_bynode=0.8, colsample_bytree=0.4,early_stopping_rounds=50, gamma=0.01, eta=0.2,max_delta_step=0, \n",
        "                          max_depth=10, min_child_weight=2, missing=None,n_estimators=100, n_jobs=1, nthread=None,objective='binary:logistic', random_state=500, \n",
        "                          reg_alpha=0.05,reg_lambda=2, scale_pos_weight=1, seed=0, silent=None, subsample=0.5, verbosity=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEkC8TDPGdje"
      },
      "source": [
        "## Fitting the model to the DATA\n",
        "eventually i've trained the model with all the train set because it gave me much better results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVu4cmhwO29h"
      },
      "source": [
        "model.fit(train_data,train_labels, eval_metric='auc', verbose=True,eval_set=evalset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ypurjk7qNTAz"
      },
      "source": [
        "## evaluating the model after tuning parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErHTQGad2nWG"
      },
      "source": [
        "## Using GridSearchCV for optimizing parameters\n",
        "\n",
        "## Round 1\n",
        "*  'max_depth': [3, 5, 10]\n",
        "*  'learning_rate':[0.1, 0.3, 0.5]\n",
        "*  'colsample_bytree':[0.1, 0.3, 0.5]\n",
        "*  'gamma':[0.001, 0.0001]\n",
        "*  'alpha' :[3,5,10]\n",
        "\n",
        "**output**: Best parameters set found on development set:\n",
        "{'alpha': 3, 'colsample_bytree': 0.5, 'gamma': 0.001, 'learning_rate': 0.1, 'max_depth': 10}\n",
        "\n",
        "## Round 2\n",
        "*   'reg_lambda' : [0.0, 1.0 , 10.0]\n",
        "*   'scale_pos_weight' : [1,3,5]\n",
        "*   'alpha' : [1,3]\n",
        "*   'gamma':[0.01, 0.001, 0.006]\n",
        "*   'colsample_bytree':[0.5, 0.7]\n",
        "*   'learning_rate':[0.1]\n",
        "*   'max_depth': [3, 5, 10]\n",
        "*   n_jobs = 10\n",
        "*   cv = 3\n",
        "*   'reg_alpha':[0.0, 1.0 , 10.0]\n",
        "\n",
        "**output**: (alpha=3, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "colsample_bynode=1, colsample_bytree=0.5, gamma=0.006,\n",
        "learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
        "min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
        "nthread=None, objective='binary:logistic', random_state=0,\n",
        "reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1, seed=None,\n",
        "silent=None, subsample=1, verbosity=1)\n",
        "\n",
        "## Round 3\n",
        "*   'reg_lambda' : [0.0, 1.0 , 10.0]\n",
        "*   'scale_pos_weight' : [1, 10, 100]\n",
        "*   'alpha' : [1,3]\n",
        "*   'gamma':[ 0.006, 0.009]\n",
        "*   'colsample_bytree':[0.5]\n",
        "*   'learning_rate':[0.1]\n",
        "*   'max_depth': [3, 5, 10]\n",
        "*   n_jobs = 10\n",
        "*   cv = 3\n",
        "\n",
        "**output**:alpha=1, base_score=0.5, booster='gbtree', colsample_bylevel=1,colsample_bynode=1, colsample_bytree=0.5, gamma=0.0009,\n",
        "learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
        "min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
        "nthread=None, objective='binary:logistic', random_state=0,\n",
        "reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=1, seed=None,\n",
        "silent=None, subsample=1, verbosity=1)\n",
        "\n",
        "## Round 4\n",
        "*   'alpha' : [0.5,1]\n",
        "*   'min_child_weight' : [1, 3, 5]\n",
        "*   'max_delta_step' : [0, 1, 2]\n",
        "*   n_jobs = -1\n",
        "*   cv = cv_k\n",
        "*   seed : [0, 7, 42]\n",
        "\n",
        "**output:** (*alpha=0.5*, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=0.5, gamma=0.0009,\n",
        "              learning_rate=0.1, *max_delta_step=0*, max_depth=3,\n",
        "              *min_child_weight=3*, missing=None, n_estimators=100, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0.0, reg_lambda=1.0, scale_pos_weight=1, *seed=42*,\n",
        "              silent=None, subsample=1, verbosity=1)\n",
        "\n",
        "## Round 5\n",
        "*    'n_estimators' = [100,500,1000]\n",
        "*    'early_stopping_rounds' = [10, 20]\n",
        "*    'random_state' = [0, 10, 100]\n",
        "\n",
        "**output:** alpha=1, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=0.5,\n",
        "              early_stopping_rounds=10, gamma=0.0009, learning_rate=0.1,\n",
        "              max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
        "              n_estimators=100, n_jobs=1, nthread=None,\n",
        "              objective='binary:logistic', random_state=100, reg_alpha=0.0,\n",
        "              reg_lambda=1.0, scale_pos_weight=1, seed=None, silent=None,\n",
        "              subsample=1, verbosity=1)\n",
        "\n",
        "## Round 6\n",
        "*   'min_child_weight' : [2,3,4]\n",
        "*   'gamma':[ 0.01, 0.009]\n",
        "*   'colsample_bytree':[0.4,0.5]\n",
        "*   'subsample':[0.5, 0.7,1]\n",
        "*   'random_state' = [100, 1000, 500]\n",
        "*   'reg_lambda' : [0.5, 1.0 , 5]\n",
        "\n",
        "** output**: alpha=1, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=0.4,\n",
        "              early_stopping_rounds=10, gamma=0.01, learning_rate=0.1,\n",
        "              max_delta_step=0, max_depth=3, min_child_weight=4, missing=None,\n",
        "              n_estimators=100, n_jobs=1, nthread=None,\n",
        "              objective='binary:logistic', random_state=500, reg_alpha=0.0,\n",
        "              reg_lambda=1.0, scale_pos_weight=1, seed=None, silent=None,\n",
        "              subsample=0.5, verbosity=1)\n",
        "\n",
        "## for later\n",
        "'colsample_bylevel':[1,0.5,0.8],\n",
        "              'colsample_bynode':[1,0.5,0.8], 'colsample_bytree':[0.4,0.5],'subsample':[0.4,0.5]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10ZWi3d7Km2m"
      },
      "source": [
        "param_grid = {'gamma':[0.01,0.05,0.007],'early_stopping_rounds':[50,70],'reg_alpha':[0.1,0.05],'colsample_bylevel':[0.5,0.8], 'colsample_bynode':[0.5,0.8], 'colsample_bytree':[0.4,0.5],'subsample':[0.6,0.5], 'max_depth':[3,5,6],'n_extimators':[100,500]}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN5lgjS7Ob9O"
      },
      "source": [
        "## Tunning parameters using Grid search CV - very slow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_gsnSrH2kcP"
      },
      "source": [
        "search = GridSearchCV(model, param_grid, scoring='roc_auc', cv=3, verbose=1, n_jobs=-1)\n",
        "search.fit(x_train,y_train)\n",
        "search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSLTxndG0y6"
      },
      "source": [
        "# creating the submission file\n",
        "The submission file contains table with the proteins and the predicted value from the XGB classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EULl09pT_MR1"
      },
      "source": [
        "\n",
        "def create_submission_file(filename, model, test_data, Ids):\n",
        "    predictions = model.predict_proba(test_data)[:,1]\n",
        "    my_submission = pd.DataFrame({'Id': Ids, 'prediction': predictions})\n",
        "    my_submission.to_csv(filename, index=False)\n",
        "\n",
        "create_submission_file(\"mysubmission-1NN.csv\", model, test_data, test_Ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UACm-Xg3_MX7"
      },
      "source": [
        "results = model.evals_result()\n",
        "\n",
        "\n",
        "# plot learning curves\n",
        "plt.plot(results['validation_0']['auc'], label='train')\n",
        "#plt.plot(results['validation_1']['auc'], label='test')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}